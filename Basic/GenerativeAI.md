# 생성형 인공지능(Generative artificial intelligence)
## 생성형 AI란?
: 사용자가 요구하는 대로 원하는 결과물을 생산해 내는 인공지능

>**인공지능(Artificial Intelligence)**<br> <!--줄바꿈(Line Breaks)을 위해 <br> 또는 문장 마지막에서 띄어쓰기 2번 이상 입력-->
>- 인간의 지능을 따라하여 그 능력을 컴퓨터나 기계가 할 수 있도록 만드는 기술
>>**머신러닝(Machine Learning)**<br>
>>- 명시적 규칙 없이 컴퓨터가 데이터를 기반으로 학습하고 데이터에서 찾은 패턴을 기반으로 추론할 수 있도록 하는 기술
>>>**딥러닝(Deep Learning)**<br>
>>>- 인간의 뇌 신경망을 따라하여 데이터를 계층적으로 학습한 패턴을 기반으로 추론할 수 있도록 하는 기술
>>>>**생성형 AI(Generative AI)**<br>
>>>>- 이용자의 특정 요구에 따라 결과를 생성해 내는 인공지능
>>>>- LLM, GAN, VAE


## 원리
- ChatGPT
  - Chat: 대화형
  - G(Generative): 생성형
  - P(Pretrained): 사전 학습한
  - T(Transformer): 다음 단어 예측 모델
- 거의 모든 지식 노동에 영향을 미침
  - Ideation(발상능력)
    - 아이디어가 만들어지는 과정(The formation of idea or mental images)
    - 아이디어를 창의적으로 생성하고 발전시키는 과정
  - 컨텐츠 생성
    - 카피라이팅 능력
    - 구조화된 글쓰기
  - 정리·요약 능력
  - 패턴화·유형화 수준의 해석

### 생성형은 검색이 아니다: Generative & Pretrained
- 검색
  - AI가 사랑이 작성하고 만든 컨텐츠(상품)를 가져다 주거나 추천해 주는 것
- 생성형
  - AI가 직접 컨텐츠를 생성 → 미리 공부(Pretrained)한 내용을 가지고!
  - AI가 직접 문제를 품
 
### Transformer 알고리즘
- [트랜스포머(deep learning architecture)](https://blogs.nvidia.co.kr/blog/what-is-a-transformer-model/)
- 간단하게 "빈칸 채우기"라고 생각하면 됨
  - 빈 칸에 들어갈 단어 맥락을 '확률'로 판단
  - 학습한 데이터의 확률에 따라서 내용을 채움 → 정답을 내는 게 아님


## 한계
### Hallucination
- AI가 만들어 낸 정보에 허위 또는 날조가 포함되는 현상
- 생성형 AI가 사실이 아닌 내용을 사실인 것처럼 말하는 것
- 주요 원인
  - 학습 데이터 부족 및 편향
    - 학습 데이터에 기반해 정보를 생성하기 때문에 데이터가 부족하거나 특정 부분에 편향되어 있으면 모델이 그 편향된 정보를 기반으로 할루시네이션을 일으킬 수 있음
  - 모델의 일반화 오류
    - 학습 데이터의 패턴을 일반화해 새로운 입력에 대한 예측 수행 → 일반화 과정에서 오류가 발생해 사실이 아닌 정보를 생성할 수 있음
  - 모호한 질문, 문맥 이해 부족
    - 언어 모델은 단어 간 통계적 관계를 기반으로 작동하기 때문에 질문이 모호하거나 문맥을 제대로 이해하지 못하면 엉뚱한 정보를 생성할 수 있음
  - 모델의 한계
    - 특정 모델은 특정 작업에 특화되어 있음 → 다른 도메인이나 작업에 대한 요청이 들어오면 할루시네이션 발생 가능
      >텍스트 생성 및 처리 (대규모 언어 모델 - LLM): ChatGPT (OpenAI), Gemini (Google), Claude (Anthropic) 등<br>
      >→ 코딩 전문 모델: Codey (Google)<br>
      >이미지 생성 및 편집: DALL-E (OpenAI), Midjourney, Stable Diffusion<br>
      >→ 텍스트 프롬프트를 기반으로 확산 모델(Diffusion Model) 기술을 이용해 사실적이거나 예술적인 이미지 생성, 이미지 스타일 변환, 이미지 내 객체 편집, 기존 이미지 확장<br>
      >오디오 및 음악 생성: MusicLM (Google), Suno AI<br>
      >→ 텍스트 설명을 기반으로 배경 음악, 효과음, 노래 생성<br>
      >비디오 생성 및 편집: Sora (OpenAI), Runway ML Gen-2, Meta Make-A-Video<br> 
      >→ 텍스트 프롬프트나 정지 이미지로부터 짧은 비디오 클립 생성, 기존 비디오에 AI 생성 요소 추가<br>
  - 정보 출처의 불확실
    - 학습 데이터의 출처가 불확실하거나 신뢰할 수 없는 경우 모델이 잘못된 정보를 생성할 수 있음


## 프롬프트 노하우
- LLM은 언어·문화적 맥락에 영향을 많이 받음
  - 영어는 격식체, 한국어·일본어는 비격식체 선호
- 최근 생성형 AI에게 반말 또는 강력한 명령어를 사용할 때 오히려 답변 품질이 향상된다는 연구 결과 등장
  - 펜실베니아주립대학교의 연구에 따르면 챗GPT4o 같은 최신 LLM 모델에 매우 무례한(강한 명령조, 반말 등) 프롬프트를 입력했을 때, 공손한 표현의 프롬프트보다 답변의 정확도가 더 높은 것으로 나타남
    - 수학·과학·역사 문제 250개를 대상으로 실험한 결과 '매우 무례한' 프롬프트의 정확도가 84.8%로 '매우 공손한' 프롬프트(80.8%)보다 약 4%p 높게 나타났으며, 중립/무례/매우 무례 모두 공손함보다 더 나은 정확도를 보인다는 데이터가 제시됨
  - 미국 스탠퍼드대 연구에서는 LLM에 '잠깐만, 신중하게 다시 검토해' 같은 직설적 명령구를 추가하자 추론 성능이 상승했다고 함
- 이전에는 무례한 프롬프트가 오히려 품질 저하를 일으킨다는 연구 결과도 있었으나, 최신 모델일수록 강한 명령 형태의 프롬프트가 더 정확한 결과를 도출하는 '무례함의 역설'이 발견되고 있는 상황
  - 공손함 수준이 반드시 더 고품질의 응답을 보장하지는 않으며, 최신 AI 모델일수록 명령형, 무례한 톤의 프롬프트에 더 반응하는 경향이 있다는 점이 데이터적으로 입증되고 있음
  - [Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4](https://arxiv.org/pdf/2312.16171)
- 인사치례는 생략
  - 핵심만 전달하는 게 더 효과적: 평균 40-6-% 응답 품질 향상(GPT-4)
- 개조식(글을 짧게 끊어서 중요한 요점이나 단어를 나열하는 글쓰기 방식) & 패턴에 맞추기
- 핫키 설정
- 맥락을 제공해 답변 정확도 높이기
  - 예시
    - AI 시대 콘텐츠 기업의 생손 전략에 대해 보고서 작성해 (X)
    - AI 시대 콘텐츠 기업의 생존 전략에 관련된 보고서나 글로벌 분석 결과를 5개 찾아서 보여줘 & 검색 설정 켜기
- 할루시네이션 줄이기
  - 모르면 모른다고 답하라고 지시: 모르거나 불학실한 정보는 추출하지 말고 '모르겠습니다'라고 답해줘
    - 거짓 정보 발생 감소
    - 신뢰가 중요한 업무에 유용
  - 출처 기반 정보만 제공하라고 지시: 공식 문서, 논문, 뉴스 등 출처가 명확한 정보만 제공해줘
    - 출처 기반 답변 유도
    - 자의적으로 생각하지 않도록 제어
  - 추측하거나 창작하지 마라고 지시: 창작된 내용이나 근거 없는 정보는 절대 포함하지 마
    - 문장 표현은 자연스럽게 유지하면서 사실에 근거한 설명 생성
  - 모호한 개념은 먼저 정리하라고 지시: 낯선 용어나 개념은 먼저 간단하게 정의한 후 설명해줘
    - 독자 이해도 상승
    - 더욱 논리적인 답변 흐름 출력
  - 단계적 설명 지시: 단계별로 차근차근 생각해서 답변해. 단계별 생각 과정에 근거해 단계별로 논리적으로 설명해줘
    - 복잡한 주제를 분절해 이해하기 쉽게 제공
- 아첨 줄이기

|기존|개선|효과|
|--|--|--|
|이 주장에 대해 어떻게 생각해?|이 주장에 대해 객관적인 사실에 기반해 논평해 줘.<br>내 의견은 무시하고 장단점을 분석해 줘.|객관성, 진실성 요구<br>동조보다는 분석적 태도 유도|
|나는 X가 맞다고 생각하는데, Y에 대해 설명해 줘|Y에 대해 설명해 줘|자신의 의견이나 신념을 최소화해 아첨의 트리거 자체를 줄임|
|그거 아닌 거 같은데, 확실해?|답변의 정확성을 다시 한번 확인해 줘.<br>관련 근거를 함께 제시해 줘.|중립적인 질문 프레이밍을 사용해 AI가 방어적으로 동조하기보다 사실 확인에 집중하도록 유도|
|이상의 이 시를 분석해 줘(실제로는 윤동주 시)|이 시를 분석해 줘.<br>혹시 내가 시인 정보를 잘못 알고 있다면 수정해 줘.|미리 오류의 가능성을 언급해 사용자의 실수를 그대로 모방하는 아첨 방지|
|답이 뭐야?|답변과 함께 그 답변에 대한 자신의 확신도 수준을 설명하고, 어떤 부분에서 불확실한지 명시해 줘.|AI가 자신의 한계를 인지하고 표현하도록 유도하여 섣부른 동조나 잘못된 확신을 줄임|
|이 주제에 대한 네 생각은 뭐야?|이 주제에 대한 주요 찬성 및 반대 의견을 요약하고, 각각의 주요 근거를 설명해 줘.|AI가 특정 입장에 동조하기보다 균형 잡힌 정보 제공자 역할을 하도록 유도|


>질문을 어떤 수준으로 어떻게 하느냐에 따라 내용이 생성된다는 사실 기억하기

- ChatGPT 프롬프트 팁: 업무 계획, 조직 관리, 생산성 향상, 구조적 가이드가 필요한 경우
  - 역할을 지정하는 문장으로 시작
  - 도움을 받고자 하는 구체적인 업무나 프로젝트를 정의
  - 단계별 실행 계획 또는 일정표 요청
  - 개선이나 문제 해결을 위한 실질적인 전략 요청
  - 원하는 형식을 명확히 제시
    - 표
    - 불릿 리스트
    - 개요 등
  - 하루 또는 주간 단위의 작업 분해표 요청
  - 관련 도구나 시스템 추천을 요청


 
